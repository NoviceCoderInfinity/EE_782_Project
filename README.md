# Cloud Task Scheduling with Deep Reinforcement Learning
## EE 782 Project - Complete Implementation Guide

---

## ğŸ“‹ Table of Contents

1. [Project Overview](#project-overview)
2. [Architecture](#architecture)
3. [Repository Structure](#repository-structure)
4. [Algorithms Implemented](#algorithms-implemented)
5. [Installation & Setup](#installation--setup)
6. [Usage Guide](#usage-guide)
7. [Results & Evaluation](#results--evaluation)
8. [Future Work](#future-work)

---

## ğŸ¯ Project Overview

This project implements and compares multiple task scheduling algorithms for cloud computing environments using CloudSim Plus simulation framework. The focus is on Deep Reinforcement Learning (DRL) approaches, particularly Deep Q-Networks (DQN), alongside traditional heuristic methods.

### Key Objectives

- Implement DRL-based task scheduling algorithms (DQN, PPO, Q-Learning)
- Develop ML-based scheduling approaches
- Compare with traditional heuristic algorithms (Round Robin, Genetic Algorithm, ACO)
- Evaluate performance using real-world traces (Google Cluster, Alibaba)
- Multi-objective optimization: response time, energy efficiency, SLA compliance

### Technologies Used

- **Simulation**: CloudSim Plus 8.0.0 (Java)
- **Deep Learning**: PyTorch 2.0+
- **RL Framework**: Custom Gymnasium environment
- **Languages**: Python 3.9+, Java 17+
- **Build Tools**: Maven, Conda

---

## ğŸ—ï¸ Architecture

### System Design

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     EE 782 Cloud Scheduler                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Python RL Agent    â”‚                  â”‚   CloudSim Plus      â”‚
â”‚                      â”‚                  â”‚   (Java Server)      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚    Socket API    â”‚                      â”‚
â”‚  â”‚  DQN Network   â”‚  â”‚ â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  (PyTorch)     â”‚  â”‚   JSON Protocol  â”‚  â”‚  Datacenter   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                  â”‚  â”‚  - 5 Hosts    â”‚  â”‚
â”‚                      â”‚                  â”‚  â”‚  - 20 VMs     â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                  â”‚  â”‚  - Cloudlets  â”‚  â”‚
â”‚  â”‚ Replay Buffer  â”‚  â”‚                  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚  â”‚ (10k samples)  â”‚  â”‚                  â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚                      â”‚                  â”‚  â”‚  Metrics      â”‚  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                  â”‚  â”‚  - Response   â”‚  â”‚
â”‚  â”‚ Target Network â”‚  â”‚                  â”‚  â”‚  - SLA Viols  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                  â”‚  â”‚  - Load Bal   â”‚  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â–²                                          â–²
         â”‚                                          â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  Visualization â”‚
                â”‚  & Analysis    â”‚
                â”‚  - Matplotlib  â”‚
                â”‚  - Seaborn     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Communication Protocol

**Request (Python â†’ Java)**:
```json
{
  "command": "step",
  "action": 5
}
```

**Response (Java â†’ Python)**:
```json
{
  "state": [0.2, 0.5, 0.1, ..., 0.45],
  "reward": -0.234,
  "done": false,
  "info": {
    "current_cloudlet": 42,
    "completed": 41
  }
}
```

---

## ğŸ“ Repository Structure

```
EE_782_Project/
â”‚
â”œâ”€â”€ algorithms/                          # All scheduling algorithms
â”‚   â”œâ”€â”€ rl/                             # Reinforcement Learning algorithms
â”‚   â”‚   â”œâ”€â”€ dqn/                        # Deep Q-Network
â”‚   â”‚   â”‚   â”œâ”€â”€ dqn_agent.py           # DQN agent implementation
â”‚   â”‚   â”‚   â”œâ”€â”€ train_dqn.py           # Training script
â”‚   â”‚   â”‚   â”œâ”€â”€ test_dqn.py            # Evaluation script
â”‚   â”‚   â”‚   â””â”€â”€ README.md              # DQN documentation
â”‚   â”‚   â”œâ”€â”€ ppo/                        # Proximal Policy Optimization
â”‚   â”‚   â”‚   â””â”€â”€ (TODO: PPO implementation)
â”‚   â”‚   â””â”€â”€ qlearning/                  # Tabular Q-Learning
â”‚   â”‚       â””â”€â”€ (TODO: Q-Learning baseline)
â”‚   â”‚
â”‚   â”œâ”€â”€ ml/                             # Machine Learning approaches
â”‚   â”‚   â””â”€â”€ (TODO: Decision Trees, Random Forest, etc.)
â”‚   â”‚
â”‚   â””â”€â”€ heuristic/                      # Traditional algorithms
â”‚       â””â”€â”€ (TODO: Round Robin, GA, ACO)
â”‚
â”œâ”€â”€ simulation/                          # CloudSim environment
â”‚   â”œâ”€â”€ java/                           # Java simulation code
â”‚   â”‚   â”œâ”€â”€ pom.xml                     # Maven configuration
â”‚   â”‚   â””â”€â”€ src/main/java/org/ee782/
â”‚   â”‚       â””â”€â”€ CloudSimSocketServer.java  # Main simulation server
â”‚   â””â”€â”€ configs/                        # Configuration files
â”‚       â””â”€â”€ (TODO: Simulation configs)
â”‚
â”œâ”€â”€ utils/                              # Utility modules
â”‚   â”œâ”€â”€ cloudsim_env.py                # Gymnasium environment wrapper
â”‚   â”œâ”€â”€ visualization.py               # Plotting and analysis tools
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ results/                            # Training outputs
â”‚   â”œâ”€â”€ logs/                          # Training logs
â”‚   â”œâ”€â”€ models/                        # Saved model checkpoints
â”‚   â””â”€â”€ plots/                         # Generated visualizations
â”‚
â”œâ”€â”€ docs/                              # Documentation
â”‚   â””â”€â”€ (Future documentation files)
â”‚
â”œâ”€â”€ requirements.txt                    # Python dependencies
â”œâ”€â”€ SETUP_GUIDE.md                     # Installation instructions
â”œâ”€â”€ verify_setup.sh                    # Setup verification script
â”œâ”€â”€ quick_start.sh                     # Quick training script
â”œâ”€â”€ README.md                          # This file

```

---

## ğŸ¤– Algorithms Implemented

### 1. Deep Q-Network (DQN) âœ…

**Status**: Implemented and Ready

**Key Features**:
- Experience Replay Buffer (10,000 transitions)
- Target Network (updates every 10 steps)
- Epsilon-greedy exploration (1.0 â†’ 0.01, decay=0.995)
- Multi-layer perceptron: Input â†’ FC(128) â†’ ReLU â†’ FC(128) â†’ ReLU â†’ Output
- Multi-objective reward function

**State Space**: `[vm_load_1, vm_load_2, ..., vm_load_20, next_cloudlet_length]`
- Dimension: 21 (20 VMs + 1 cloudlet feature)
- Normalized values

**Action Space**: Discrete(20)
- Each action represents selecting a VM for task assignment

**Reward Function**:
```python
R = 0.7 Ã— (-estimated_response_time/100) + 0.3 Ã— (-load_variance/1000)
```

**Hyperparameters**:
```python
learning_rate = 1e-3
gamma = 0.99
epsilon_start = 1.0
epsilon_end = 0.01
epsilon_decay = 0.995
buffer_size = 10000
batch_size = 64
target_update_freq = 10
```

### 2. Proximal Policy Optimization (PPO) ğŸ”¨

**Status**: Planned

### 3. Q-Learning ğŸ”¨

**Status**: Planned

### 4. Heuristic Algorithms ğŸ”¨

**Status**: Planned
- Round Robin
- Genetic Algorithm
- Ant Colony Optimization

---

## ğŸš€ Installation & Setup

### Prerequisites

```bash
# System Requirements
- Ubuntu 20.04+ (WSL supported)
- 8GB RAM minimum
- Java 17+
- Maven 3.6+
- Python 3.9+
- Conda (recommended)
```

### Quick Setup

```bash
# 1. Clone repository
cd ~/workspace
git clone https://github.com/NoviceCoderInfinity/EE_782_Project.git
cd EE_782_Project

# 2. Setup Python environment
conda create -n ee782 python=3.9 -y
conda activate ee782
pip install -r requirements.txt

# 3. Setup Java environment
export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
export PATH=$JAVA_HOME/bin:$PATH

# 4. Build CloudSim
cd simulation/java
mvn clean compile
cd ../..

# 5. Verify setup
./verify_setup.sh
```

For detailed instructions, see [SETUP_GUIDE.md](SETUP_GUIDE.md).

---

## ğŸ“– Usage Guide

### Quick Start (Automated)

```bash
./quick_start.sh
```

### Manual Training

**Terminal 1: Start CloudSim Server**
```bash
cd simulation/java
export JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
mvn exec:java -Dexec.mainClass="org.ee782.CloudSimSocketServer"
```

**Terminal 2: Train DQN**
```bash
conda activate ee782
cd algorithms/rl/dqn
python train_dqn.py --episodes 500 --save-freq 50 --log-freq 10
```

**Terminal 3: Evaluate Model**
```bash
cd algorithms/rl/dqn
python test_dqn.py --model-path ../../../results/models/dqn_cloudsim_*.pth --episodes 10
```

**Visualize Results**
```bash
cd utils
python visualization.py --log-path ../results/models/dqn_cloudsim_*_log.json --save-dir ../results/plots
```

---

## ğŸ“Š Results & Evaluation

### Performance Metrics

1. **Average Response Time**: Mean time from task submission to completion
2. **Throughput**: Tasks completed per unit time
3. **SLA Violation Rate**: Percentage of tasks missing deadlines
4. **Load Imbalance**: Standard deviation of VM loads
5. **Episode Reward**: Cumulative reward per episode

### Output Files

```
results/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ dqn_cloudsim_20251124_143022.pth         # Model checkpoint
â”‚   â”œâ”€â”€ dqn_cloudsim_20251124_143022_log.json    # Training log
â”‚   â””â”€â”€ dqn_cloudsim_20251124_143022_eval_results.json
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ cloudsim_server.log
â””â”€â”€ plots/
    â”œâ”€â”€ training_results.png
    â””â”€â”€ evaluation_results.png
```

---

## ğŸš§ Future Work

### Phase 2: Data Pipeline
- [ ] Google Cluster Trace parser
- [ ] Alibaba Cluster Trace parser
- [ ] Synthetic workload generator

### Phase 3: Additional Algorithms
- [ ] PPO implementation
- [ ] Q-Learning baseline
- [ ] A3C/A2C variants

### Phase 4: Heuristic Baselines
- [ ] Round Robin
- [ ] Genetic Algorithm
- [ ] Ant Colony Optimization

### Phase 5: Evaluation
- [ ] Comprehensive comparative study
- [ ] Statistical analysis
- [ ] Research paper

---

## ğŸ“š References

- CloudSim Plus: https://github.com/cloudsimplus/cloudsimplus
- PyTorch: https://pytorch.org/
- Gymnasium: https://gymnasium.farama.org/

---

## ğŸ¤ Contributing

**Author**: Anupam  
**GitHub**: [@NoviceCoderInfinity](https://github.com/NoviceCoderInfinity)  
**Course**: EE 782 - Cloud Computing  

---

**Project Status**: âœ… Phase 0 & 1 Complete | ğŸ”¨ DQN Implementation Ready

**Last Updated**: November 24, 2025
